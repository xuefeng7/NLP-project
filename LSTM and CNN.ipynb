{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import string\n",
    "import numpy as np; np.random.seed(7)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word 2 vec repre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_map = {}\n",
    "with open('data/vectors_pruned.200.txt', 'r') as src:\n",
    "    src = src.read().strip().split('\\n')\n",
    "    for line in src:\n",
    "        wv = line.strip().split(' ')\n",
    "        word = wv.pop(0)\n",
    "        w2v_map[word] = np.array(list(map(float, wv)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2i_map = {}\n",
    "for i, key in enumerate(w2v_map.keys()):\n",
    "    w2i_map[key] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(w2i_map, open('data/word_idx_map.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### map Q idx to context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_matrix = np.zeros(( len((w2v_map.keys())), 200 ))\n",
    "counter = 0\n",
    "for _, val in w2v_map.items():\n",
    "    w2v_matrix[counter] = val\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl.dump(w2i_map, open('data/w2v_matrix.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def w2v(w):\n",
    "    return w2v_matrix[w2i_map[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sen2w(sen):\n",
    "    processed = []\n",
    "    sen = re.sub(r'[!#\\'(),/:?\\{}]', ' ', sen).strip().split()\n",
    "    if len(sen) > 100:\n",
    "        sen = sen[:100]\n",
    "    for w in sen:\n",
    "        # ignore date\n",
    "        if re.match(r'\\d{1,}-\\d{1,}-\\d{1,}', w):\n",
    "            continue\n",
    "        if re.match(r'\\d{1,}:\\d{1,}', w):\n",
    "            continue\n",
    "        if w in w2i_map:\n",
    "            processed += [w]\n",
    "        else:\n",
    "            separated = re.findall(r\"[^\\W\\d_]+|\\d+|[=`%$\\^\\-@;\\[&_*>\\].<~|+\\d+]\", w)\n",
    "            if len(set(separated)) == 1:\n",
    "                continue\n",
    "            if separated.count('*') > 3 or separated.count('=') > 3:\n",
    "                continue\n",
    "            for separate_w in separated:\n",
    "                if separate_w in w2i_map:\n",
    "                    processed += [separate_w]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fixed context len = 125\n",
    "context_repre = {}\n",
    "with open('data/text_tokenized.txt', 'r') as src:\n",
    "    src = src.read().strip().split('\\n')\n",
    "    for line in src:\n",
    "        context = line.strip().split('\\t')\n",
    "        qid = context.pop(0)\n",
    "        if len(context) == 1:\n",
    "            context_repre[int(qid)] = {'t': sen2w(context[0]), 'b': None}\n",
    "        else:\n",
    "            len_title = len(context[0])\n",
    "            if len_title >= 125:\n",
    "                context_repre[int(qid)] = {'t':sen2w(context[0])[:125], 'b': None}\n",
    "            else:\n",
    "                context_repre[int(qid)] = {'t':sen2w(context[0]), 'b': sen2w(context[1])[:125 - len_title]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### len of context ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_lens = []\n",
    "for k, v in context_repre.items():\n",
    "    t, b = v['t'], v['b']\n",
    "    if not v['b']:\n",
    "        b = []\n",
    "    all_lens += [len(t)+len(b)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 633,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 633,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all(np.array(all_lens) < 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train_random.txt', header=None, delimiter='\\t', names=['Q','Q+','Q-'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>Q+</th>\n",
       "      <th>Q-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>262144</td>\n",
       "      <td>211039</td>\n",
       "      <td>227387 413633 113297 356390 256881 145638 2962...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>491522</td>\n",
       "      <td>65911</td>\n",
       "      <td>155119 402211 310669 383107 131731 299465 1633...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240299</td>\n",
       "      <td>168608 390642</td>\n",
       "      <td>368007 70009 48077 376760 438005 228888 142340...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>196614</td>\n",
       "      <td>205184</td>\n",
       "      <td>334471 163710 376791 441664 159963 406360 4300...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360457</td>\n",
       "      <td>321532</td>\n",
       "      <td>151863 501857 217578 470017 125838 31836 42066...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Q             Q+                                                 Q-\n",
       "0  262144         211039  227387 413633 113297 356390 256881 145638 2962...\n",
       "1  491522          65911  155119 402211 310669 383107 131731 299465 1633...\n",
       "2  240299  168608 390642  368007 70009 48077 376760 438005 228888 142340...\n",
       "3  196614         205184  334471 163710 376791 441664 159963 406360 4300...\n",
       "4  360457         321532  151863 501857 217578 470017 125838 31836 42066..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_set_pair_with_idx(df):\n",
    "    idx_set = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        idx_set[row['Q']] = {'pos': np.array(list(map(int, row['Q+'].split(' ')))), \\\n",
    "                             'neg': np.array(list(map(int, row['Q-'].split(' '))))}\n",
    "    return idx_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_idx_set = build_set_pair_with_idx(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contxt2vec(title, body=None):\n",
    "    \n",
    "    if body == None:\n",
    "        body = []\n",
    "    \n",
    "#     v = np.zeros( (len(title) + len(body), 200) )\n",
    "#     counter = 0\n",
    "    title_v = np.zeros( (len(title), 200) )\n",
    "    \n",
    "    for i, t in enumerate(title):\n",
    "        title_v[i] = w2v(t)\n",
    "    \n",
    "    if len(body) > 0:\n",
    "        body_v = np.zeros( (len(body), 200) )\n",
    "        for i, b in enumerate(body):\n",
    "            body_v[i] = w2v(b)\n",
    "    \n",
    "        return title_v, body_v\n",
    "    \n",
    "    return title_v, None\n",
    "    \n",
    "#     for t in title:\n",
    "#         v[counter] = w2v(t)\n",
    "#         counter += 1\n",
    "\n",
    "#     for b in body:\n",
    "#         v[counter] = w2v(b)\n",
    "#         counter += 1\n",
    "    \n",
    "#     return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_contxt_batch(qids, idx_set):\n",
    "    \n",
    "    batch_title, batch_body = [], []\n",
    "    max_title_len, max_body_len = 0, 0\n",
    "    title_len, body_len = [], []\n",
    "    counter = 0\n",
    "    \n",
    "    for qid in qids:\n",
    "        \n",
    "        q_title, q_body = context_repre[qid]['t'], context_repre[qid]['b']\n",
    "        q_pos = idx_set[qid]['pos']\n",
    "\n",
    "        for qid_pos in q_pos:\n",
    "\n",
    "            # query Q\n",
    "            title_len += [len(q_title)]\n",
    "            batch_title += [ q_title ]\n",
    "            max_title_len = max(max_title_len, len(q_title))\n",
    "            if not q_body:\n",
    "                body_len += [0]\n",
    "                batch_body += [ [] ]\n",
    "            else:\n",
    "                batch_body += [ q_body ]\n",
    "                body_len += [len(q_body)]\n",
    "                max_body_len = max(max_body_len, len(q_body))\n",
    "                \n",
    "            # pos Q\n",
    "            title, body = context_repre[qid_pos]['t'], context_repre[qid_pos]['b']\n",
    "            title_len += [len(title)]\n",
    "            batch_title += [ title ]\n",
    "            max_title_len = max(max_title_len, len(title))\n",
    "            if not body:\n",
    "                body_len += [0]\n",
    "                batch_body += [ [] ]\n",
    "            else:\n",
    "                batch_body += [ body ]\n",
    "                body_len += [len(body)]\n",
    "                max_body_len = max(max_body_len, len(body))\n",
    "        \n",
    "            # neg Q\n",
    "            \n",
    "            q_neg = idx_set[qid]['neg']\n",
    "            q_neg_sample_indices = np.random.choice(range(100), size=20)\n",
    "            q_random_neg = q_neg[q_neg_sample_indices]\n",
    "            \n",
    "            for qid_neg in q_random_neg:\n",
    "                title, body = context_repre[qid_neg]['t'], context_repre[qid_neg]['b']\n",
    "                title_len += [len(title)]\n",
    "                batch_title += [ title ]\n",
    "                max_title_len = max(max_title_len, len(title))\n",
    "                if not body:\n",
    "                    body_len += [0]\n",
    "                    batch_body += [ [] ]\n",
    "                else:\n",
    "                    batch_body += [ body ]\n",
    "                    body_len += [len(body)]\n",
    "                    max_body_len = max(max_body_len, len(body))\n",
    "    \n",
    "    # (max_seq_len, batch_size, feature_len)\n",
    "    padded_batch_title = np.zeros(( max_title_len, len(batch_title), 200)) \n",
    "    padded_batch_body = np.zeros(( max_body_len, len(batch_body),  200))\n",
    "    \n",
    "    for i, (title, body) in enumerate(zip(batch_title, batch_body)):\n",
    "        title_repre, body_repre = contxt2vec(title, body)\n",
    "        padded_batch_title[:title_len[i], i] = title_repre\n",
    "        if len(body) > 0:\n",
    "            padded_batch_body[:body_len[i], i] = body_repre\n",
    "    \n",
    "    return padded_batch_title, padded_batch_body, np.array(title_len).reshape(-1,1), np.array(body_len).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_batch(qids, idx_set):\n",
    "    \n",
    "    total_pos_len = 0\n",
    "    for qid in qids:\n",
    "        total_pos_len += len(idx_set[qid]['pos'])\n",
    "    \n",
    "    # per batch element x: vstack, [query_Q x 1; pos_Q x 1; neg_Q x 20]\n",
    "    # per batch element y: vstack, [query_Q=-1; pos_Q=1; neg_Q=0]\n",
    "    batch_x = np.zeros(( total_pos_len * 22, 124, 200 ))\n",
    "    seq_len = np.zeros(total_pos_len * 22)\n",
    "    \n",
    "    counter = 0\n",
    "    for qid in qids:\n",
    "        \n",
    "        q_title, q_body = context_repre[qid]['t'], context_repre[qid]['b']\n",
    "        q_pos = idx_set[qid]['pos']\n",
    "\n",
    "        # usually one sample\n",
    "        for qid_pos in q_pos:\n",
    "            title, body = context_repre[qid_pos]['t'], context_repre[qid_pos]['b']\n",
    "            # query Q\n",
    "            if not q_body:\n",
    "                q_seq_len = len(q_title)\n",
    "            else:\n",
    "                q_seq_len = len(q_title) + len(q_body)\n",
    "            seq_len[counter] = q_seq_len\n",
    "            batch_x[counter, :q_seq_len] = contxt2vec(q_title, q_body)\n",
    "            counter += 1\n",
    "            # pos Q\n",
    "            if not body:\n",
    "                pos_q_seq_len = len(title)\n",
    "            else:\n",
    "                pos_q_seq_len = len(title) + len(body)\n",
    "            seq_len[counter] = pos_q_seq_len\n",
    "            batch_x[counter, :pos_q_seq_len] = contxt2vec(title, body)\n",
    "            counter += 1\n",
    "        \n",
    "            q_neg = idx_set[qid]['neg']\n",
    "            q_neg_sample_indices = np.random.choice(range(100), size=20)\n",
    "            q_random_neg = q_neg[q_neg_sample_indices]\n",
    "            # neg Q\n",
    "            for qid_neg in q_random_neg:\n",
    "                title, body = context_repre[qid_neg]['t'], context_repre[qid_neg]['b']\n",
    "                if not body:\n",
    "                    neg_q_seq_len = len(title)\n",
    "                else:\n",
    "                    neg_q_seq_len = len(title) + len(body)\n",
    "                seq_len[counter] = neg_q_seq_len\n",
    "                batch_x[counter, : neg_q_seq_len] = contxt2vec(title, body)\n",
    "                counter += 1\n",
    "    \n",
    "    return batch_x, seq_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_annotations(path, K_neg=20, prune_pos_cnt=10):\n",
    "    lst = [ ]\n",
    "    with open(path) as fin:\n",
    "        for line in fin:\n",
    "            parts = line.split(\"\\t\")\n",
    "            pid, pos, neg = parts[:3]\n",
    "            pos = pos.split()\n",
    "            neg = neg.split()\n",
    "            if len(pos) == 0 or (len(pos) > prune_pos_cnt and prune_pos_cnt != -1): continue\n",
    "            if K_neg != -1:\n",
    "                np.random.shuffle(neg)\n",
    "                neg = neg[:K_neg]\n",
    "            s = set()\n",
    "            qids = [ ]\n",
    "            qlabels = [ ]\n",
    "            for q in neg:\n",
    "                if q not in s:\n",
    "                    qids.append(q)\n",
    "                    qlabels.append(0 if q not in pos else 1)\n",
    "                    s.add(q)\n",
    "            for q in pos:\n",
    "                if q not in s:\n",
    "                    qids.append(q)\n",
    "                    qlabels.append(1)\n",
    "                    s.add(q)\n",
    "            lst.append((pid, qids, qlabels))\n",
    "\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Evaluation():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def Precision(self, precision_at):\n",
    "        scores = []\n",
    "        for item in self.data:\n",
    "            temp = item[:precision_at]\n",
    "            if any(val==1 for val in item):\n",
    "                scores.append(sum([1 if val==1 else 0 for val in temp])*1.0 / len(temp) if len(temp) > 0 else 0.0)\n",
    "        return sum(scores)/len(scores) if len(scores) > 0 else 0.0\n",
    "\n",
    "    def MAP(self):\n",
    "        scores = []\n",
    "        missing_MAP = 0\n",
    "        for item in self.data:\n",
    "            temp = []\n",
    "            count = 0.0\n",
    "            for i,val in enumerate(item):\n",
    "                if val == 1:\n",
    "                    count += 1.0\n",
    "                    temp.append(count/(i+1))\n",
    "                if len(temp) > 0:\n",
    "                    scores.append(sum(temp) / len(temp))\n",
    "                else:\n",
    "                    missing_MAP += 1\n",
    "        return sum(scores)/len(scores) if len(scores) > 0 else 0.0\n",
    "\n",
    "    def MRR(self):\n",
    "        scores = []\n",
    "        for item in self.data:\n",
    "            for i,val in enumerate(item):\n",
    "                if val == 1:\n",
    "                    scores.append(1.0/(i+1))\n",
    "                    break\n",
    "\n",
    "        return sum(scores)/len(scores) if len(scores) > 0 else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, layer_type, kernel_size=None):\n",
    "        \n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        if layer_type == 'lstm':\n",
    "            self.layer_type = 'lstm'\n",
    "            self.embedding_layer = nn.LSTM(input_size, hidden_size)\n",
    "            self.tanh = nn.Tanh()\n",
    "        elif layer_type == 'cnn':\n",
    "            self.layer_type = 'cnn'\n",
    "            self.embedding_layer = nn.Sequential(\n",
    "                        nn.Conv1d(in_channels = 200,\n",
    "                                  out_channels = self.hidden_size,\n",
    "                                  kernel_size = kernel_size),\n",
    "                        nn.Tanh())\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (Variable(torch.zeros(batch_size, 1, self.hidden_size)), \\\n",
    "                Variable(torch.zeros(batch_size, 1, self.hidden_size)))\n",
    "\n",
    "    def forward(self, context, seq_len):\n",
    "            \n",
    "        if self.layer_type == 'lstm':\n",
    "            \n",
    "            \n",
    "            lstm_out, self.hidden = self.embedding_layer(context, (self.tanh(self.hidden[0]), \\\n",
    "                                                                   self.tanh(self.hidden[1])))\n",
    "            mask = build_mask(seq_len, 124)\n",
    "            embeddings = torch.sum(lstm_out * Variable(torch.FloatTensor(mask)), dim=1) \\\n",
    "                / Variable(torch.FloatTensor(np.sum(mask, axis=1)))\n",
    "        \n",
    "        elif self.layer_type == 'cnn':\n",
    "            \n",
    "            cnn_out = self.embedding_layer(context.view(-1, context.size()[2], context.size()[1]))\n",
    "            mask = build_mask(seq_len - self.kernel_size + 1, 124 - self.kernel_size + 1)\n",
    "            embeddings = torch.sum(cnn_out.view(-1, 124 - self.kernel_size + 1, self.hidden_size) \\\n",
    "                                   * Variable(torch.FloatTensor(mask)), dim=1) \\\n",
    "                / Variable(torch.FloatTensor(np.sum(mask, axis=1)))\n",
    "        \n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cos_sim(qv, qv_):\n",
    "    return torch.sum(qv * qv_, dim=1) / (torch.sqrt(torch.sum(qv ** 2, dim=1)) * torch.sqrt(torch.sum(qv_ ** 2, dim=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def criterion(embeddings):\n",
    "    \n",
    "    # a batch of embeddings\n",
    "    num_block = embeddings.size()[0] // 22\n",
    "    loss = 0\n",
    "    for i in range(num_block):\n",
    "        block_embeddings = embeddings[ i * 22: (i + 1) * 22 ]\n",
    "        qs = block_embeddings[0]\n",
    "        qs_ = block_embeddings[1:22]\n",
    "        cos_scores = cos_sim(qs.expand(21, 240), qs_)\n",
    "        pos_score = cos_scores[0]\n",
    "        neg_score = torch.max(cos_scores[1:])\n",
    "        diff = neg_score - pos_score + 1 # margin=1\n",
    "        if diff.data[0] > 0:\n",
    "            loss += diff\n",
    "    return loss / num_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mask(seq_len, max_len):\n",
    "    mask = []\n",
    "    for i, s in enumerate(seq_len):\n",
    "        s_mask = np.zeros((max_len, 1))\n",
    "        s_mask[:int(s)] = np.ones((int(s), 1))\n",
    "        mask += [s_mask]\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(layer_type, batch_size=25, num_epoch=100):\n",
    "    \n",
    "    if layer_type == 'lstm':\n",
    "        embedding_layer = EmbeddingLayer(200, 240, 'lstm')\n",
    "    elif layer_type == 'cnn':\n",
    "        embedding_layer = EmbeddingLayer(200, 240, 'cnn', kernel_size=3)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(embedding_layer.parameters(), lr=0.005)\n",
    "    \n",
    "    qids = list(train_idx_set.keys())[:640]\n",
    "    num_batch = len(qids) // batch_size\n",
    "    \n",
    "    for epoch in range(1, num_epoch + 1):\n",
    "        \n",
    "        for batch_idx in range(1, num_batch + 1):\n",
    "            \n",
    "            batch_x_qids = qids[ ( batch_idx - 1 ) * batch_size: batch_idx * batch_size]\n",
    "            start = time.time()\n",
    "            print ('processing batch {}'.format(batch_idx))\n",
    "            padded_batch_x, seq_len = process_batch(batch_x_qids, train_idx_set)\n",
    "            print ('processing batch costs:', time.time() - start)\n",
    "            if layer_type == 'lstm':\n",
    "                embedding_layer.hidden = embedding_layer.init_hidden(padded_batch_x.shape[0])\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            start = time.time()\n",
    "            qs = Variable(torch.FloatTensor(padded_batch_x))\n",
    "            embeddings = embedding_layer(qs, seq_len)\n",
    "            print ('embedding costs:', time.time() - start)\n",
    "\n",
    "            loss = criterion(embeddings)\n",
    "            print ('-------------------------------')\n",
    "            print ('epoch:{}/{}, batch:{}/{}, loss:{}'.format(epoch, num_epoch, batch_idx, num_batch, loss.data[0]))\n",
    "            print ('-------------------------------')\n",
    "            start = time.time()\n",
    "            loss.backward()\n",
    "            print ('backprop costs:', time.time() - start)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (2) into shape (73,200)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-630-ecd2fc2d8aaf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-629-264d36bdb11c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(layer_type, batch_size, num_epoch)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'processing batch {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m             \u001b[0mpadded_batch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x_qids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_idx_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'processing batch costs:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayer_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'lstm'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-fe23e3ed4db0>\u001b[0m in \u001b[0;36mprocess_batch\u001b[0;34m(qids, idx_set)\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mq_seq_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_title\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mseq_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mbatch_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mq_seq_len\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontxt2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_title\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;31m# pos Q\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (2) into shape (73,200)"
     ]
    }
   ],
   "source": [
    "train('lstm', num_epoch=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qids = list(train_idx_set.keys())\n",
    "batch_x_qids = qids[:10]\n",
    "batch_x, seq_len = process_batch(batch_x_qids, train_idx_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.101999, -0.104434, -0.012801, ...,  0.034353, -0.013605,\n",
       "        -0.037034],\n",
       "       [ 0.00388 , -0.07965 , -0.044619, ..., -0.021587,  0.023161,\n",
       "        -0.135637],\n",
       "       [-0.026436,  0.013091, -0.037213, ..., -0.059916,  0.027431,\n",
       "         0.020814],\n",
       "       ..., \n",
       "       [-0.026436,  0.013091, -0.037213, ..., -0.059916,  0.027431,\n",
       "         0.020814],\n",
       "       [ 0.00388 , -0.07965 , -0.044619, ..., -0.021587,  0.023161,\n",
       "        -0.135637],\n",
       "       [-0.026436,  0.013091, -0.037213, ..., -0.059916,  0.027431,\n",
       "         0.020814]])"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x[0][:int(seq_len[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qs = Variable(torch.FloatTensor(batch_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = EmbeddingLayer(200, 240, 'lstm')\n",
    "embedding_layer.hidden = embedding_layer.init_hidden(batch_x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = embedding_layer(qs, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = build_mask(seq_len, 124)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = nn.Sequential(\n",
    "            nn.Conv1d(in_channels = 200,\n",
    "                      out_channels = 240,\n",
    "                      kernel_size = 3),\n",
    "            nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_embedded = cnn(qs.view(-1, 200, 124)).view(-1, 122, 240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = build_mask(seq_len - 3 + 1, 122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.2164e-03 -2.9757e-03 -4.3598e-03  ...   5.5581e-03  2.8719e-03  8.5967e-03\n",
       "-9.0396e-04 -4.5738e-03  1.3033e-03  ...  -5.9795e-03 -1.0130e-03  5.0258e-03\n",
       "-4.3827e-03  4.5129e-03 -9.6274e-03  ...  -5.7902e-03  5.3599e-03  2.4672e-03\n",
       "                ...                   ⋱                   ...                \n",
       "-3.2514e-03 -2.0969e-04 -4.0796e-03  ...   3.6529e-03 -3.3661e-05  8.5487e-03\n",
       " 1.2756e-03  1.2373e-04  5.6213e-04  ...  -9.9583e-04 -2.3388e-04  9.8959e-03\n",
       "-6.0902e-03 -2.7618e-03 -8.5951e-03  ...  -6.0784e-03 -2.5088e-03 -1.8907e-03\n",
       "[torch.FloatTensor of size 242x240]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(cnn_embedded * Variable(torch.FloatTensor(mask)), dim=1) \\\n",
    "                / Variable(torch.FloatTensor(np.sum(mask, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "   71\n",
       "   63\n",
       "   95\n",
       "   82\n",
       "   89\n",
       "   79\n",
       "   46\n",
       "   79\n",
       "   79\n",
       "   82\n",
       "   88\n",
       "   74\n",
       "   75\n",
       "   44\n",
       "   90\n",
       "   54\n",
       "   94\n",
       "   97\n",
       "   76\n",
       "   44\n",
       "   94\n",
       "   74\n",
       "   68\n",
       "   40\n",
       "   79\n",
       "   98\n",
       "   74\n",
       "   68\n",
       "   97\n",
       "  102\n",
       "   78\n",
       "   70\n",
       "   51\n",
       "   94\n",
       "   91\n",
       "   95\n",
       "   92\n",
       "   92\n",
       "   58\n",
       "   80\n",
       "   67\n",
       "   72\n",
       "   64\n",
       "   66\n",
       "   93\n",
       "   80\n",
       "   47\n",
       "   55\n",
       "   72\n",
       "   90\n",
       "   13\n",
       "   85\n",
       "   82\n",
       "   88\n",
       "   99\n",
       "   66\n",
       "   61\n",
       "   35\n",
       "   72\n",
       "   86\n",
       "   79\n",
       "   77\n",
       "   47\n",
       "   83\n",
       "   38\n",
       "   56\n",
       "   93\n",
       "   37\n",
       "   23\n",
       "   56\n",
       "   84\n",
       "   91\n",
       "   99\n",
       "   27\n",
       "  101\n",
       "   13\n",
       "   79\n",
       "   79\n",
       "   47\n",
       "   40\n",
       "   85\n",
       "   83\n",
       "   47\n",
       "   78\n",
       "   85\n",
       "   59\n",
       "   64\n",
       "   87\n",
       "   60\n",
       "   58\n",
       "   81\n",
       "   72\n",
       "  102\n",
       "   89\n",
       "   93\n",
       "   52\n",
       "   91\n",
       "   56\n",
       "   31\n",
       "   92\n",
       "   68\n",
       "   72\n",
       "   81\n",
       "   61\n",
       "   31\n",
       "   92\n",
       "   74\n",
       "   82\n",
       "   86\n",
       "   63\n",
       "   79\n",
       "   76\n",
       "   94\n",
       "   94\n",
       "   63\n",
       "   96\n",
       "   83\n",
       "   92\n",
       "   92\n",
       "   58\n",
       "   35\n",
       "  107\n",
       "   86\n",
       "   60\n",
       "   88\n",
       "   45\n",
       "   70\n",
       "   83\n",
       "   42\n",
       "   55\n",
       "   68\n",
       "   23\n",
       "   70\n",
       "   53\n",
       "   60\n",
       "   83\n",
       "   99\n",
       "   59\n",
       "   75\n",
       "   75\n",
       "   71\n",
       "   61\n",
       "   90\n",
       "   98\n",
       "   47\n",
       "   94\n",
       "   32\n",
       "   66\n",
       "   60\n",
       "   59\n",
       "   54\n",
       "   49\n",
       "   99\n",
       "   94\n",
       "   33\n",
       "   40\n",
       "   72\n",
       "   76\n",
       "   83\n",
       "   94\n",
       "   90\n",
       "  102\n",
       "  102\n",
       "   87\n",
       "   49\n",
       "   93\n",
       "   43\n",
       "  100\n",
       "   54\n",
       "   92\n",
       "   72\n",
       "   67\n",
       "  102\n",
       "   65\n",
       "   87\n",
       "   67\n",
       "   29\n",
       "   94\n",
       "   93\n",
       "   82\n",
       "  103\n",
       "   58\n",
       "   53\n",
       "  103\n",
       "   79\n",
       "   63\n",
       "   60\n",
       "   82\n",
       "  100\n",
       "   97\n",
       "   85\n",
       "   83\n",
       "   90\n",
       "   99\n",
       "   73\n",
       "   88\n",
       "   92\n",
       "  103\n",
       "   51\n",
       "   55\n",
       "   56\n",
       "   61\n",
       "   79\n",
       "   70\n",
       "   89\n",
       "   85\n",
       "   72\n",
       "   77\n",
       "   38\n",
       "   89\n",
       "   89\n",
       "   59\n",
       "   51\n",
       "   70\n",
       "   77\n",
       "   70\n",
       "   86\n",
       "   74\n",
       "   60\n",
       "   72\n",
       "   65\n",
       "   56\n",
       "   50\n",
       "   58\n",
       "   74\n",
       "   69\n",
       "   79\n",
       "   91\n",
       "   54\n",
       "   95\n",
       "   35\n",
       "   76\n",
       "   70\n",
       "   36\n",
       "   39\n",
       "   71\n",
       "   63\n",
       "   59\n",
       "   67\n",
       "   89\n",
       "   92\n",
       "   32\n",
       "[torch.FloatTensor of size 242x1]"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.FloatTensor(np.sum(mask, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Variable(torch.FloatTensor(242, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.0489e-28  2.8026e-45  1.5785e-36  ...   1.4013e-45  8.2920e-38  1.4013e-45\n",
       " 1.5785e-36  1.4013e-45 -2.9426e-35  ...   1.4013e-45  1.5785e-36  1.4013e-45\n",
       "-2.9432e-35  1.4013e-45  8.2920e-38  ...   1.4013e-45 -2.9429e-35  1.4013e-45\n",
       "                ...                   ⋱                   ...                \n",
       "-2.9876e-35  1.4013e-45  8.2920e-38  ...   1.4013e-45 -2.9877e-35  1.4013e-45\n",
       " 8.2920e-38  1.4013e-45  1.5785e-36  ...   1.4013e-45  8.2920e-38  1.4013e-45\n",
       " 1.5785e-36  1.4013e-45 -2.9878e-35  ...   1.4013e-45  1.5785e-36  1.4013e-45\n",
       "[torch.FloatTensor of size 242x20]"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-2.8857e-30  0.0000e+00  2.2232e-38  ...   0.0000e+00  1.1679e-39  0.0000e+00\n",
       " 2.5055e-38  0.0000e+00 -4.6708e-37  ...   0.0000e+00  2.5055e-38  0.0000e+00\n",
       "-3.0981e-37  0.0000e+00  8.7284e-40  ...   0.0000e+00 -3.0978e-37  0.0000e+00\n",
       "                ...                   ⋱                   ...                \n",
       "-3.3569e-37  0.0000e+00  9.3169e-40  ...   0.0000e+00 -3.3570e-37  0.0000e+00\n",
       " 9.0131e-40  0.0000e+00  1.7157e-38  ...   0.0000e+00  9.0131e-40  0.0000e+00\n",
       " 4.9327e-38  0.0000e+00 -9.3368e-37  ...   0.0000e+00  4.9327e-38  0.0000e+00\n",
       "[torch.FloatTensor of size 242x20]"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a / Variable(torch.FloatTensor(np.sum(mask, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-05 *\n",
       " -6.2883\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(cos_sim(pooled[0].expand(21,240), pooled[1:22])[1:]) - cos_sim(pooled[0].expand(21,240), pooled[1:22])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Variable' object has no attribute 'req'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-566-335760f58cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpooled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fallthrough_methods\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Variable' object has no attribute 'req'"
     ]
    }
   ],
   "source": [
    "pooled.req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3.6748e+00  3.1938e+00  6.7675e+00  ...   1.0466e+00 -2.3588e+00 -3.7777e+00\n",
       " 4.8605e+00  3.8674e+00  9.5440e+00  ...   1.3729e+00 -3.6389e+00 -5.2017e+00\n",
       " 6.8265e+00  4.0363e+00  1.0813e+01  ...   2.2500e+00 -3.9408e+00 -6.3748e+00\n",
       "                ...                   ⋱                   ...                \n",
       " 1.2466e+01  3.2535e+00  1.1807e+01  ...   3.0170e+00 -4.1371e+00 -6.4224e+00\n",
       " 1.2466e+01  3.2535e+00  1.1807e+01  ...   3.0170e+00 -4.1371e+00 -6.4224e+00\n",
       " 1.2466e+01  3.2535e+00  1.1807e+01  ...   3.0170e+00 -4.1371e+00 -6.4224e+00\n",
       "[torch.FloatTensor of size 124x240]"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(out, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.5000  1.0000\n",
       " 2.3333  2.6667\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(Variable(torch.FloatTensor([[[1,2],[3,4]],[[5,6],[7,8]]])) * Variable(torch.FloatTensor([[[1],[0]],[[0],[1]]])), dim=1) / Variable(torch.FloatTensor([[2],[3]]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
