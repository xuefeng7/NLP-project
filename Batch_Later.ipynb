{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import string\n",
    "import numpy as np; np.random.seed(7)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_map = {}\n",
    "with open('data/vectors_pruned.200.txt', 'r') as src:\n",
    "    src = src.read().strip().split('\\n')\n",
    "    for line in src:\n",
    "        wv = line.strip().split(' ')\n",
    "        word = wv.pop(0)\n",
    "        w2v_map[word] = np.array(list(map(float, wv)))\n",
    "\n",
    "w2i_map = {}\n",
    "for i, key in enumerate(w2v_map.keys()):\n",
    "    w2i_map[key] = i\n",
    "\n",
    "w2v_matrix = np.zeros(( len((w2v_map.keys())), 200 ))\n",
    "counter = 0\n",
    "for _, val in w2v_map.items():\n",
    "    w2v_matrix[counter] = val\n",
    "    counter += 1\n",
    "\n",
    "def w2v(w):\n",
    "    return w2v_matrix[w2i_map[w]]\n",
    "\n",
    "def sen2w(sen):\n",
    "    processed = []\n",
    "    sen = sen.strip().split()\n",
    "    if len(sen) > 100:\n",
    "        sen = sen[:100]\n",
    "    for w in sen:\n",
    "        #ignore date\n",
    "        if re.match(r'\\d{1,}-\\d{1,}-\\d{1,}', w):\n",
    "            continue\n",
    "        if re.match(r'\\d{1,}:\\d{1,}', w):\n",
    "            continue\n",
    "        \n",
    "        if w in w2i_map:\n",
    "            processed += [w]\n",
    "        else:\n",
    "            separated = re.findall(r\"[^\\W\\d_]+|\\d+|[=`%$\\^\\-@;\\[&_*>\\].<~|+\\d+]\", w)\n",
    "            if len(set(separated)) == 1:\n",
    "                continue\n",
    "            if separated.count('*') > 3 or separated.count('=') > 3:\n",
    "                continue\n",
    "            for separate_w in separated:\n",
    "                if separate_w in w2i_map:\n",
    "                    processed += [separate_w]\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fixed context len = 125\n",
    "context_repre = {}\n",
    "with open('data/text_tokenized.txt', 'r') as src:\n",
    "    src = src.read().strip().split('\\n')\n",
    "    for line in src:\n",
    "        context = line.strip().split('\\t')\n",
    "        qid = context.pop(0)\n",
    "        if len(context) == 1:\n",
    "            context_repre[int(qid)] = {'t': sen2w(context[0]), 'b': None}\n",
    "        else:\n",
    "            context_repre[int(qid)] = {'t':sen2w(context[0]), 'b': sen2w(context[1])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_set_pair_with_idx(df):\n",
    "    idx_set = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        idx_set[row['Q']] = {'pos': np.array(list(map(int, row['Q+'].split(' ')))), \\\n",
    "                             'neg': np.array(list(map(int, row['Q-'].split(' '))))}\n",
    "    return idx_set\n",
    "\n",
    "train_df = pd.read_csv('data/train_random.txt', header=None, delimiter='\\t', names=['Q','Q+','Q-'])\n",
    "train_idx_set = build_set_pair_with_idx(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contxt2vec(title, body=None):\n",
    "    \n",
    "    if body == None:\n",
    "        body = []\n",
    "    \n",
    "    title_v = np.zeros( (len(title), 200) )\n",
    "    \n",
    "    for i, t in enumerate(title):\n",
    "        title_v[i] = w2v(t)\n",
    "    \n",
    "    if len(body) > 0:\n",
    "        body_v = np.zeros( (len(body), 200) )\n",
    "        for i, b in enumerate(body):\n",
    "            body_v[i] = w2v(b)\n",
    "    \n",
    "        return title_v, body_v\n",
    "    \n",
    "    return title_v, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_contxt_batch(qids, idx_set):\n",
    "    \n",
    "    batch_title, batch_body = [], []\n",
    "    max_title_len, max_body_len = 0, 0\n",
    "    title_len, body_len = [], []\n",
    "    counter = 0\n",
    "    \n",
    "    for qid in qids:\n",
    "        \n",
    "        q_title, q_body = context_repre[qid]['t'], context_repre[qid]['b']\n",
    "        q_pos = idx_set[qid]['pos']\n",
    "\n",
    "        for qid_pos in q_pos:\n",
    "\n",
    "            # query Q\n",
    "            title_len += [len(q_title)]\n",
    "            batch_title += [ q_title ]\n",
    "            max_title_len = max(max_title_len, len(q_title))\n",
    "            if not q_body:\n",
    "                body_len += [len(q_title)]\n",
    "                batch_body += [ q_title ]\n",
    "            else:\n",
    "                batch_body += [ q_body ]\n",
    "                body_len += [len(q_body)]\n",
    "                max_body_len = max(max_body_len, len(q_body))\n",
    "                \n",
    "            # pos Q\n",
    "            title, body = context_repre[qid_pos]['t'], context_repre[qid_pos]['b']\n",
    "            title_len += [len(title)]\n",
    "            batch_title += [ title ]\n",
    "            max_title_len = max(max_title_len, len(title))\n",
    "            if not body:\n",
    "                body_len += [len(title)]\n",
    "                batch_body += [ title ]\n",
    "            else:\n",
    "                batch_body += [ body ]\n",
    "                body_len += [len(body)]\n",
    "                max_body_len = max(max_body_len, len(body))\n",
    "        \n",
    "            # neg Q\n",
    "            \n",
    "            q_neg = idx_set[qid]['neg']\n",
    "            q_neg_sample_indices = np.random.choice(range(100), size=20)\n",
    "            q_random_neg = q_neg[q_neg_sample_indices]\n",
    "            \n",
    "            for qid_neg in q_random_neg:\n",
    "                title, body = context_repre[qid_neg]['t'], context_repre[qid_neg]['b']\n",
    "                title_len += [len(title)]\n",
    "                batch_title += [ title ]\n",
    "                max_title_len = max(max_title_len, len(title))\n",
    "                if not body:\n",
    "                    body_len += [len(title)]\n",
    "                    batch_body += [ title ]\n",
    "                else:\n",
    "                    batch_body += [ body ]\n",
    "                    body_len += [len(body)]\n",
    "                    max_body_len = max(max_body_len, len(body))\n",
    "    \n",
    "    # (max_seq_len, batch_size, feature_len)\n",
    "    padded_batch_title = np.zeros(( max_title_len, len(batch_title), 200)) \n",
    "    padded_batch_body = np.zeros(( max_body_len, len(batch_body),  200))\n",
    "    \n",
    "    for i, (title, body) in enumerate(zip(batch_title, batch_body)):\n",
    "        title_repre, body_repre = contxt2vec(title, body)\n",
    "        padded_batch_title[:title_len[i], i] = title_repre\n",
    "        padded_batch_body[:body_len[i], i] = body_repre\n",
    "    \n",
    "    return padded_batch_title, padded_batch_body, np.array(title_len).reshape(-1,1), np.array(body_len).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_mask(seq_len):\n",
    "    mask = []\n",
    "    for i, s in enumerate(seq_len):\n",
    "        s_mask = np.zeros((np.max(seq_len), 1))\n",
    "        s_mask[:int(s)] = np.ones((int(s), 1))\n",
    "        mask += [s_mask]\n",
    "    return mask\n",
    "\n",
    "def cos_sim(qv, qv_):\n",
    "    return torch.sum(qv * qv_, dim=1) / (torch.sqrt(torch.sum(qv ** 2, dim=1)) * torch.sqrt(torch.sum(qv_ ** 2, dim=1)))\n",
    "\n",
    "def criterion(embeddings):\n",
    "    \n",
    "    # a batch of embeddings\n",
    "    num_block = embeddings.size()[0] // 22\n",
    "    loss = 0\n",
    "    for i in range(num_block):\n",
    "        block_embeddings = embeddings[ i * 22: (i + 1) * 22 ]\n",
    "        qs = block_embeddings[0]\n",
    "        qs_ = block_embeddings[1: 22]\n",
    "        cos_scores = cos_sim(qs.expand(21, 240), qs_)\n",
    "        pos_score = cos_scores[0]\n",
    "        neg_score = torch.max(cos_scores[1:])\n",
    "        diff = neg_score - pos_score + 1 # margin=1\n",
    "        if diff.data[0] > 0:\n",
    "            loss += diff\n",
    "            \n",
    "    return loss / num_block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EmbeddingLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, layer_type, kernel_size=None):\n",
    "        \n",
    "        super(EmbeddingLayer, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.kernel_size = kernel_size\n",
    "        \n",
    "        if layer_type == 'lstm':\n",
    "            self.layer_type = 'lstm'\n",
    "            self.embedding_layer = nn.LSTM(input_size, hidden_size)\n",
    "            self.tanh = nn.Tanh()\n",
    "        elif layer_type == 'cnn':\n",
    "            self.layer_type = 'cnn'\n",
    "            self.embedding_layer = nn.Sequential(\n",
    "                        nn.Conv1d(in_channels = 200,\n",
    "                                  out_channels = self.hidden_size,\n",
    "                                  kernel_size = kernel_size),\n",
    "                        nn.Tanh())\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return (Variable(torch.zeros(1, batch_size, self.hidden_size)), \\\n",
    "                Variable(torch.zeros(1, batch_size, self.hidden_size)))\n",
    "\n",
    "    def forward(self, context, seq_len):\n",
    "            \n",
    "        if self.layer_type == 'lstm':\n",
    "            \n",
    "            \n",
    "            lstm_out, self.hidden = self.embedding_layer(context, (self.tanh(self.hidden[0]), \\\n",
    "                                                                   self.tanh(self.hidden[1])))\n",
    "            \n",
    "            mask = build_mask(seq_len)\n",
    "            mask = Variable(torch.FloatTensor(mask)).view(lstm_out.size()[0], -1, 1)\n",
    "            embeddings = torch.sum(lstm_out * mask, dim=0) / ( torch.sum(mask, dim=0) + 1e-8)\n",
    "\n",
    "#             mask = build_mask(seq_len)\n",
    "#             embeddings = torch.sum(lstm_out.view(-1, lstm_out.size()[0], self.hidden_size) \\\n",
    "#                                    * Variable(torch.FloatTensor(mask)), dim=1) \\\n",
    "#                 / Variable(torch.FloatTensor(np.sum(mask, axis=1)))\n",
    "        \n",
    "#         elif self.layer_type == 'cnn':\n",
    "            \n",
    "#             cnn_out = self.embedding_layer(context.view(-1, context.size()[2], context.size()[1]))\n",
    "#             mask = build_mask(seq_len - self.kernel_size + 1, 124 - self.kernel_size + 1)\n",
    "#             embeddings = torch.sum(cnn_out.view(-1, 124 - self.kernel_size + 1, self.hidden_size) \\\n",
    "#                                    * Variable(torch.FloatTensor(mask)), dim=1) \\\n",
    "#                 / Variable(torch.FloatTensor(np.sum(mask, axis=1)))\n",
    "        \n",
    "            return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(layer_type, batch_size=25, num_epoch=100):\n",
    "    \n",
    "    if layer_type == 'lstm':\n",
    "        embedding_layer = EmbeddingLayer(200, 240, 'lstm')\n",
    "    elif layer_type == 'cnn':\n",
    "        embedding_layer = EmbeddingLayer(200, 240, 'cnn', kernel_size=3)\n",
    "        \n",
    "    optimizer = torch.optim.Adam(embedding_layer.parameters(), lr=0.005)\n",
    "    \n",
    "    qids = list(train_idx_set.keys())\n",
    "    num_batch = len(qids) // batch_size\n",
    "    \n",
    "    for epoch in range(1, num_epoch + 1):\n",
    "        \n",
    "        for batch_idx in range(1, num_batch + 1):\n",
    "            \n",
    "            batch_x_qids = qids[ ( batch_idx - 1 ) * batch_size: batch_idx * batch_size]\n",
    "            start = time.time()\n",
    "            print ('processing batch {}'.format(batch_idx))\n",
    "            batch_title, batch_body, title_len, body_len = process_contxt_batch(batch_x_qids, train_idx_set)\n",
    "            print ('processing batch costs:', time.time() - start)\n",
    "            \n",
    "            if layer_type == 'lstm':\n",
    "                embedding_layer.hidden = embedding_layer.init_hidden(batch_title.shape[1])\n",
    "            \n",
    "            start = time.time()\n",
    "            \n",
    "            title_qs = Variable(torch.FloatTensor(batch_title))\n",
    "            body_qs = Variable(torch.FloatTensor(batch_body))\n",
    "            \n",
    "            title_embeddings = embedding_layer(title_qs, title_len)\n",
    "            body_embeddings = embedding_layer(body_qs, body_len)\n",
    "            \n",
    "            contxt_embeddings = ( title_embeddings + body_embeddings ) / 2\n",
    "            print ('embedding costs:', time.time() - start)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(contxt_embeddings)\n",
    "\n",
    "            print ('-------------------------------')\n",
    "            print ('epoch:{}/{}, batch:{}/{}, loss:{}'.format(epoch, num_epoch, batch_idx, num_batch, loss.data[0]))\n",
    "            print ('-------------------------------')\n",
    "            start = time.time()\n",
    "            loss.backward()\n",
    "            print ('backprop costs:', time.time() - start)\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing batch 1\n",
      "processing batch costs: 0.49100685119628906\n",
      "embedding costs: 10.933600902557373\n",
      "-------------------------------\n",
      "epoch:1/100, batch:1/508, loss:1.000967025756836\n",
      "-------------------------------\n",
      "backprop costs: 8.534204244613647\n",
      "processing batch 2\n",
      "processing batch costs: 1.0649118423461914\n",
      "embedding costs: 7.769730091094971\n",
      "-------------------------------\n",
      "epoch:1/100, batch:2/508, loss:1.000191330909729\n",
      "-------------------------------\n",
      "backprop costs: 5.0320963859558105\n",
      "processing batch 3\n",
      "processing batch costs: 0.8480250835418701\n",
      "embedding costs: 13.439337968826294\n",
      "-------------------------------\n",
      "epoch:1/100, batch:3/508, loss:1.000032901763916\n",
      "-------------------------------\n",
      "backprop costs: 9.811716079711914\n",
      "processing batch 4\n",
      "processing batch costs: 1.7102789878845215\n",
      "embedding costs: 8.348220825195312\n",
      "-------------------------------\n",
      "epoch:1/100, batch:4/508, loss:1.0000029802322388\n",
      "-------------------------------\n",
      "backprop costs: 5.67284893989563\n",
      "processing batch 5\n",
      "processing batch costs: 1.806920051574707\n",
      "embedding costs: 9.952331066131592\n",
      "-------------------------------\n",
      "epoch:1/100, batch:5/508, loss:1.0000028610229492\n",
      "-------------------------------\n",
      "backprop costs: 8.917108058929443\n",
      "processing batch 6\n",
      "processing batch costs: 0.8796088695526123\n",
      "embedding costs: 28.69900894165039\n",
      "-------------------------------\n",
      "epoch:1/100, batch:6/508, loss:1.0000032186508179\n",
      "-------------------------------\n",
      "backprop costs: 29.422084093093872\n",
      "processing batch 7\n",
      "processing batch costs: 1.190157175064087\n",
      "embedding costs: 5.557406902313232\n",
      "-------------------------------\n",
      "epoch:1/100, batch:7/508, loss:1.0000008344650269\n",
      "-------------------------------\n",
      "backprop costs: 3.6454379558563232\n",
      "processing batch 8\n",
      "processing batch costs: 0.5850780010223389\n",
      "embedding costs: 6.039541959762573\n",
      "-------------------------------\n",
      "epoch:1/100, batch:8/508, loss:1.0000044107437134\n",
      "-------------------------------\n",
      "backprop costs: 3.8392090797424316\n",
      "processing batch 9\n",
      "processing batch costs: 0.35542726516723633\n",
      "embedding costs: 4.086977005004883\n",
      "-------------------------------\n",
      "epoch:1/100, batch:9/508, loss:1.0000226497650146\n",
      "-------------------------------\n",
      "backprop costs: 2.815669059753418\n",
      "processing batch 10\n",
      "processing batch costs: 0.5180568695068359\n",
      "embedding costs: 10.26206088066101\n",
      "-------------------------------\n",
      "epoch:1/100, batch:10/508, loss:1.0000017881393433\n",
      "-------------------------------\n",
      "backprop costs: 8.053822994232178\n",
      "processing batch 11\n",
      "processing batch costs: 0.5103390216827393\n",
      "embedding costs: 6.564903259277344\n",
      "-------------------------------\n",
      "epoch:1/100, batch:11/508, loss:1.000003695487976\n",
      "-------------------------------\n",
      "backprop costs: 4.285251140594482\n",
      "processing batch 12\n",
      "processing batch costs: 0.742379903793335\n",
      "embedding costs: 22.68799090385437\n",
      "-------------------------------\n",
      "epoch:1/100, batch:12/508, loss:1.0000032186508179\n",
      "-------------------------------\n",
      "backprop costs: 25.598448038101196\n",
      "processing batch 13\n",
      "processing batch costs: 1.898494005203247\n",
      "embedding costs: 7.228547811508179\n",
      "-------------------------------\n",
      "epoch:1/100, batch:13/508, loss:0.9999977946281433\n",
      "-------------------------------\n",
      "backprop costs: 4.81076192855835\n",
      "processing batch 14\n",
      "processing batch costs: 0.686460018157959\n",
      "embedding costs: 5.764949798583984\n",
      "-------------------------------\n",
      "epoch:1/100, batch:14/508, loss:0.9999967217445374\n",
      "-------------------------------\n",
      "backprop costs: 3.914193868637085\n",
      "processing batch 15\n",
      "processing batch costs: 0.5582840442657471\n",
      "embedding costs: 7.72124171257019\n",
      "-------------------------------\n",
      "epoch:1/100, batch:15/508, loss:1.0000011920928955\n",
      "-------------------------------\n",
      "backprop costs: 4.69818902015686\n",
      "processing batch 16\n",
      "processing batch costs: 0.6809787750244141\n",
      "embedding costs: 63.95613884925842\n",
      "-------------------------------\n",
      "epoch:1/100, batch:16/508, loss:1.0000120401382446\n",
      "-------------------------------\n",
      "backprop costs: 65.16525912284851\n",
      "processing batch 17\n",
      "processing batch costs: 1.2716946601867676\n",
      "embedding costs: 17.972468852996826\n",
      "-------------------------------\n",
      "epoch:1/100, batch:17/508, loss:1.0000039339065552\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-d6be9ebd6959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-189-465550d0d1d5>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(layer_type, batch_size, num_epoch)\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'-------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'backprop costs:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train('lstm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qids = list(train_idx_set.keys())[0:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_title, batch_body, title_len, body_len = process_contxt_batch(qids, train_idx_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title_qs = Variable(torch.FloatTensor(batch_title))\n",
    "body_qs = Variable(torch.FloatTensor(batch_body))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_layer = EmbeddingLayer(200, 240, 'lstm')\n",
    "embedding_layer.hidden = embedding_layer.init_hidden(batch_title.shape[1])\n",
    "\n",
    "title_embeddings = embedding_layer(title_qs, title_len)\n",
    "body_embeddings = embedding_layer(body_qs, body_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = (title_embeddings + body_embeddings) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-02 *\n",
       "-0.0380  1.2984  0.2760  ...  -2.6460  2.4250 -0.6759\n",
       " 0.2273  1.2945  0.4926  ...  -2.7629  2.4335 -0.6174\n",
       " 0.0910  1.7504  0.5326  ...  -2.3675  2.3776 -0.8221\n",
       "          ...             â‹±             ...          \n",
       " 0.1120  1.7249  0.7047  ...  -2.5319  2.4124 -0.5000\n",
       " 0.4159  1.1858  0.5571  ...  -2.8192  2.3473 -0.1939\n",
       "-0.2448  1.8618  0.8149  ...  -2.5857  2.4927 -0.8622\n",
       "[torch.FloatTensor of size 22x240]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[-22:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[262144,\n",
       " 491522,\n",
       " 240299,\n",
       " 196614,\n",
       " 360457,\n",
       " 425996,\n",
       " 163842,\n",
       " 393230,\n",
       " 393231,\n",
       " 491536,\n",
       " 327698,\n",
       " 121116,\n",
       " 397172,\n",
       " 294938,\n",
       " 32795,\n",
       " 32798,\n",
       " 33,\n",
       " 34,\n",
       " 229411,\n",
       " 37,\n",
       " 294951,\n",
       " 496988,\n",
       " 196650,\n",
       " 294955,\n",
       " 73107]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': array([ 66935, 426300,  70518, 232599, 523074, 210772, 229721, 421797,\n",
       "        124315,  69105, 248750,  70052, 206788, 248606, 294643,   2340,\n",
       "         57833, 237004, 245933, 256280, 346767,   5084,  16776,  55312,\n",
       "        100586,  53443, 136515, 132076, 340324, 157574, 378966,  94040,\n",
       "        342049, 286386, 256085, 406437, 426281, 367553, 416229, 276123,\n",
       "        397066, 116051, 231825, 306014, 253084,  29443, 110394,   6424,\n",
       "        407490,  53489, 489072, 205811,  21303, 377515, 208037,  66606,\n",
       "        206277, 246931, 335508, 507425, 393560, 429556, 352150, 331768,\n",
       "         67155,   6307, 192036, 396483, 315431, 376003, 448796,  87677,\n",
       "        391839, 160160, 278122, 360817, 510617,  73323, 331227,  70037,\n",
       "        417418, 367338,  92541, 520528, 237451, 230574, 248240, 322035,\n",
       "        445612, 124040, 516399, 150639, 453936, 405564, 452362, 326452,\n",
       "         82445, 167025, 104373, 486989]), 'pos': array([82395])}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx_set[73107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'after upgrading to 11.10 i ca n t change the launcher icon size to smaller . i tried to change it using ccsm like described in how can i configure unity but the changes take no effects restarted tried sudo - still big icons . in the previous version of ubuntu this solution worked . how can i change the icon size btw how can i know which unity 2d vd 3d i running and switch between . edit looks like i using unity 2d'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(context_repre[73107]['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i using ubuntu one my laptop for over a half of year now and i upgraded it to 13.10 a month ago . it did n t have any major problems before . but today after few hours of work it stopped responding completly and i had to restart it . i logged on and about minute later it freezed again . now it happens every time laptop boots up . keyboard and mouse does n t work either .'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(context_repre[407490]['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, b = contxt2vec(context_repre[405564]['t'], context_repre[405564]['b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10, 200), (98, 200))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.0008\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion(c[-132:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20951"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2i_map['doesnot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.066099, -0.072827,  0.07531 , ..., -0.043089,  0.053407,\n",
       "          0.004687],\n",
       "        [ 0.066099, -0.072827,  0.07531 , ..., -0.043089,  0.053407,\n",
       "          0.004687],\n",
       "        [ 0.029121, -0.017085, -0.048705, ...,  0.000808,  0.03283 ,\n",
       "         -0.099112],\n",
       "        ..., \n",
       "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]),\n",
       " array([[ 0.091238, -0.121687, -0.018059, ...,  0.16513 , -0.005217,\n",
       "          0.059096],\n",
       "        [ 0.091238, -0.121687, -0.018059, ...,  0.16513 , -0.005217,\n",
       "          0.059096],\n",
       "        [ 0.06426 , -0.095106,  0.043716, ..., -0.013996, -0.030572,\n",
       "         -0.026798],\n",
       "        ..., \n",
       "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
       "        [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]))"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_body[:,-22],batch_body[:,-19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 0\n",
    "loss += torch.max(cos_sim(c[-22].expand(21,240), c[-21:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.9984\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
